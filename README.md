<div align="center">

<h1>Schema Sync</h1>
<h3><em>The AI Copilot for Data Integration</em></h3>

<p><strong>Unifying financial data across institutions with intelligence, transparency, and speed.</strong></p>

<!-- Badges (feel free to keep/remove) -->
<a href="http://127.0.0.1:8000/docs"><img alt="FastAPI" src="https://img.shields.io/badge/Backend-FastAPI-009688.svg"></a>
<img alt="Python" src="https://img.shields.io/badge/Python-3.10%2B-3776AB.svg">
<img alt="Frontend" src="https://img.shields.io/badge/Frontend-Next.js%20%2B%20React-000000.svg">
<img alt="License" src="https://img.shields.io/badge/License-MIT-purple.svg">

<p>Built for the <strong>EY Canada Data Integration Challenge â€“ Hack the Valley X 2025</strong></p>
</div>

---

## ğŸ§­ Table of Contents
- [Overview](#-overview)
- [Key Features](#-key-features)
- [Architecture](#-architecture)
- [Quick Start](#-quick-start)
- [API Endpoints](#-api-endpoints)
- [Detailed Workflow](#-detailed-workflow)
- [Outputs & Artifacts](#-outputs--artifacts)
- [Security & Privacy](#-security--privacy)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)
- [License](#-license)
- [Contact](#-contact)

---

## ğŸŒŸ Overview
When two banks merge, **data chaos follows**â€”each system has its own schema, column names, and formats.  
**Schema Sync** is your AI-powered copilot that **maps, merges, and validates** financial datasets across institutions, producing a **unified schema** and a **full audit trail** in minutes, not days.

> Think **GitHub Copilot**â€”but for **data mapping** and **schema reconciliation**.

---

## ğŸ¯ Key Features
- **ğŸ¤– AI Schema Matching** â€” Embedding-based NLP (OpenAI/SBERT) for semantic alignment  
- **ğŸ“‚ Multi-Format Uploads** â€” CSV, Excel (`.xlsx`, `.xls`), JSON  
- **ğŸ§© Visual Mapping Workspace** â€” Side-by-side schemas with drag-to-match + confidence scores  
- **ğŸ“ˆ Analytics Dashboard** â€” Completeness, overlaps, conflicts, and KPIs  
- **âš™ï¸ Conflict Resolver** â€” Detects mismatches, missing data, and format inconsistencies  
- **ğŸ§¾ Report Generation** â€” Excel/PDF with mappings, confidence, and lineage  
- **ğŸ›¡ï¸ Local Processing** â€” No cloud uploads; transparent by design  
- **ğŸ¨ Modern UI** â€” Next.js + Tailwind + shadcn/ui

---

## ğŸ—ï¸ Architecture

### Backend (FastAPI + Python)
- **Schema Parser** â€” Reads & normalizes schemas  
- **AI Matcher** â€” Embedding similarity (SBERT/OpenAI)  
- **Merge Engine** â€” Builds unified master schema  
- **Analytics Service** â€” Completeness/overlap/conflicts  
- **Report Generator** â€” Excel/PDF with audit trail  
- **Storage Layer** â€” Organized directories per institution

### Frontend (Next.js + React + Tailwind)
- **Guided flow:** Upload â†’ Map â†’ Merge â†’ Analyze â†’ Export  
- **Drag & Drop** for Bank A / Bank B  
- **Live Confidence View** + mapping health  
- **Responsive dashboard** with KPIs & charts

---

## ğŸš€ Quick Start

### Prerequisites
- Python **3.10+**
- Node.js **18+**
- (Optional) OpenAI API key if using OpenAI embeddings

### 1) Clone
```bash
git clone https://github.com/your-username/schema-sync.git
cd schema-sync
2) Backend (port 8000)
No requirements.txt in this repoâ€”install core deps manually:

bash
Copy code
cd backend
pip install fastapi uvicorn pandas python-multipart sentence-transformers torch openpyxl
uvicorn main:app --reload --port 8000
Docs: http://127.0.0.1:8000/docs

3) Frontend
bash
Copy code
cd ../my-app
npm install
npm run dev
Open: http://localhost:3000

Tip: If you later add an .env, keep secrets there (e.g., OPENAI_API_KEY). This project runs fine without one.

ğŸ”Œ API Endpoints
Base URL: http://127.0.0.1:8000

Method	Endpoint	What it does
POST	/run-pipeline	Run the full pipeline (parse â†’ map â†’ merge)
POST	/schemas/parse	Parse uploaded schemas (Excel â†’ JSON)
GET	/schemas/list	List available parsed schema JSONs
GET	/schemas/{name}	Read a specific schema JSON
GET	/auto-map	Run AI-based schema matching
POST	/upload	Upload files (schemas/data)

ğŸ§ª Detailed Workflow
Stage 1 â€” Table Mapping
Encode table names with Sentence-BERT, compute cosine similarity

Confidence threshold CONF_THRESHOLD = 73% â†’ Confident Match

Outputs: table_name_mapping.json, bank2_renamed_schema.json

Stage 2 â€” File â†’ Logical Table Manifest
Normalize filenames and map to canonical table tokens

Output: merge_manifest.json (file â†’ logical table, with bank label)

Stage 3 â€” Field-Level Mapping
Encode field strings (name + type + sample) and match

Outputs: field_name_mapping.json, unified_schema.json

Stage 4 â€” Raw Ingestion
Load Excel/CSV â†’ pandas; add bank_origin

Persist to SQLite (merged_banks.db)

Stage 5 â€” Transform & Merge
Apply column renames from field mapping

Standardize types (dates â†’ YYYY-MM-DD, numerics, identifiers)

Merge A+B; detect conflicts

Stage 6 â€” Conflict Resolution
Prefer non-nulls; tie-break (e.g., Bank A wins or most-recent timestamp)

Log decisions with lineage

Stage 7 â€” Reporting
Export unified dataset (CSV/Excel)

Generate Integration Report (PDF) with mappings, confidences, KPIs

ğŸ“¦ Outputs & Artifacts
table_name_mapping.json â€” table matches + confidence

field_name_mapping.json â€” column matches + confidence

unified_schema.json â€” canonical fields + lineage

merge_manifest.json â€” file â†’ logical table mapping

merged_banks.db â€” SQLite (raw + unified tables)

IntegrationReport.pdf â€” summary, KPIs, conflicts

ğŸ”’ Security & Privacy
Local-only processing; no data leaves your machine

Strict file validation (type/size)

Optional temp cleanup after export

Logs avoid sensitive content

ğŸ§° Troubleshooting
Issue	Fix
Backend wonâ€™t start	Ensure Python 3.10+, reinstall deps; check uvicorn command
Frontend blank page	Clear cache, rerun npm run dev
Mapping errors	Confirm sentence-transformers + torch installed
Excel parsing error	Install openpyxl; keep files under ~50 MB

ğŸ¤ Contributing
Fork â†’ git checkout -b feature/your-feature

Commit â†’ git commit -m "Add feature"

Push â†’ git push origin feature/your-feature

Open a Pull Request

